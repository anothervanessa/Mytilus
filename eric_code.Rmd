---
title: "Eric's Code Contributions"
output: html_notebook
---

Started April 12, 2021.

I'll put my code in this document for now.

```{r setup}
library(tidyverse)
library(adegenet)
library(ape)
library(raster)
library(strataG)
library(readxl)
```

# Ort & Pogson 2007 data

Download data from Ort and Pogson from Genbank. Make a vector for accessions listed in paper as EU028349â€“ EU029064.

```{r OrtPogson}

accs <- paste0("EU0",28349:29064)
# this is 716 sequences. Apparently too long for a single entrez query. Will do it as a for loop instead.

for(a in c(1:716)){
  print(paste(a,accs[a]))
  fetched <- entrez_fetch(db = "nuccore", id = accs[a], rettype = "fasta")
  write(fetched, file = "Ort_Pogson_2007.fasta", append = TRUE, sep = "\t")
}

```

Filter out the CO1 data

```{r Filter}

op <- read.FASTA("Ort_Pogson_2007.fasta")
op.co1 <- op[str_detect(names(op), pattern = "cox1")]
names(op.co1) <- str_extract(names(op.co1), pattern = "[A-Z]+[0-9]+[MF]")
write.FASTA(op.co1, file = "Ort_Pogson_CO1.fasta")
```

# Redo IBD analysis with new StrataG

```{r}
myt_aln<-read.FASTA("lat_sorted_seqs.fasta")
myt_aln<-as.matrix(myt_aln)
pop<-gsub(labels(myt_aln),pattern="([A-Za-z_]+)_\\d+",replacement="\\1")
pop<-gsub(pop,pattern="_",replacement="")

poporder<-unique(pop)

myt_g<-sequence2gtypes(myt_aln,strata=pop)
myt_g<-labelHaplotypes(myt_g)
pairwise<-pairwiseTest(myt_g, model = "raw", nrep=0,quietly = F, max.cores=4)
pairwise_phi<-as.dist(pairwiseMatrix(pairwise, stat = "PHIst"))
pairwise_phi <- as.matrix(pairwise_phi)[poporder, poporder]
pairwise_phi <- pairwise_phi/(1-pairwise_phi)
pairwise_phi.d <- as.dist(pairwise_phi)

pairwise_fst <- as.dist(pairwiseMatrix(pairwise, stat = "Fst"))
pairwise_fst <- as.matrix(pairwise_fst)[poporder, poporder]
pairwise_fst <- pairwise_fst/(1-pairwise_fst)
pairwise_fst.d <- as.dist(pairwise_fst)



myt_metadata<-read_xlsx("myt_metadata.xlsx",col_types = c("text","numeric","numeric"))
#myt_unique<-unique(myt_metadata[,c("locality","decimalLatitude","decimalLongitude")]) #pull out just locality and lat/longs, and get unique values
myt_metadata <- myt_metadata %>% arrange(desc(decimalLatitude))



gdist<-pointDistance(p1=myt_metadata[,c(3,2)], lonlat=T,allpairs=T)/1000 #measure great circle distance between points in kilometers

gdist<-as.dist(gdist) #convert to distance object

phi_mantel<-mantel.randtest(pairwise_phi.d,gdist)

phi_plot<- ggplot(tibble(gdist,pairwise_phi.d), aes(x=gdist,y=pairwise_phi.d)) + 
                    geom_point() + 
                    geom_smooth(method=lm) + xlab("Great Circle Distance(km)") +
                    ylab(expression(Phi["ST"]/1-Phi["ST"]))

phi_plot

fst_plot<- ggplot(tibble(gdist,pairwise_fst.d), aes(x=gdist,y=pairwise_fst.d)) + 
                    geom_point() + 
                    geom_smooth(method=lm) + xlab("Great Circle Distance(km)") +
                    ylab(expression(F["ST"]/1-F["ST"]))

fst_mantel<-mantel.randtest(pairwise_fst.d,gdist)


fst_plot



```

# MigraiNe Analysis

Migraine comes with a compilable program `Nexus2GP` that converts haplotype numbers to a genepop format. Could be done in R too, but `Nexus2GP` is probably better to ensure its in the right format.

```{r migraine}

write.nexus.data(myt_aln,file = "Mcalifornianus_210524.nex",interleaved=F)

```

Parmfile for Migraine:

```{bash parmfile1}

GenepopFileName=Mcalifornianus_210524-GP.txt
DemographicModel=LinearIBD
#next two settings describe total size of the habitat (not just the sampled area), 
#https://www.gbif.org/species/2285680
PSONMin=0 0
PSONMax=3800 0
# Neighborhood size = 50km
#3800/50 = GeoBinNbr
GeoBinNbr=76
GeoUnit= ind.km
#alternate way of specifying the habitat, not used for now
#habitatPars= 0.5 0.5 400 1 0
#habitatPars=0 0 0 300 0
#Infinite sites mutation model, will drop sites with more than 2 alleles
MutationModel=ISM

#sampling - could potentially change the sampling parameters, but not right now
#samplingSpace=,,
#samplingScale=,,
#Analysis - this will do 5 iterations of 100 (30 runs/point) points, 
#and overwrite them with 5 runs of 250 points
writeSequence= Over,Over,Over,Over,Over,Append,10
StatisticSequence=PAC
PointNumber=100,100,100,100,100,250
Nrunsperpoint=30,30,30,30,30,50
#Wide priors on Neu, Nem and g 
LowerBound=0.1,1,0
Upperbound=10,10000,1
oneDimCI= 2Nmu, 2Nm, Nb, condS2
CoreNbrForR=4
#Plots= all1DProfiles
1DProfiles=2Nmu, 2Nm, Nb, condS2, g
extrascale=Nb=logscale
graphicFormat=pdf
#writeAdHocFiles=T
```

# Migrate Code

I used the following script to automagically set up a screen and run migrate in each sub-directory
```{bash screen_migrate.sh}
#!
for s in */
do
       cd $s

        for m in */
        do
                cd $m
                echo $m
                screen -d -m migrate-n
                cd ..
        done
       cd ..
#done
```


# Processing output

## Function for bayes factor calculations
```{r bfcalcs}
# a function for calculating model selection statistics
bfcalcs<-function(df,ml="bezier.corrected"){
  df$thermodynamic<-as.numeric(df$thermodynamic)
  df$bezier.corrected<-as.numeric(df$bezier.corrected)
  df$harmonic<-as.numeric(df$harmonic)
    mlcol<-df[,ml] 
	bmvalue<-mlcol[which.max(mlcol)]
	lbf<-2*(mlcol-bmvalue)
	choice<-rank(-mlcol)
	modelprob<-exp(lbf/2)/sum(exp(lbf/2))
	dfall<-cbind(df,lbf,choice,modelprob)
	return(dfall)
}	
```


## Harvesting Likelihoods

```{r harvest_likelihoods}
wd<-"~/Datasets/dongsha_migrate/"
setwd(wd)
m<-c("panmixia","n_island","stepping_stone")
#m<-c("panmixia","n_island","dongsha_sink","dongsha_source","stepping_stone")



likelists<-list()
for(r in 1:3){
  wd1<-paste(wd,"dongsha",r,sep="")
  setwd(wd1)
  # start here if you just want to do one list
  likelist<-list() #initialize an empty list
  for(f in list.files()){
    wd2<-file.path(wd1,f)
    marglike<-data.frame(model=character(0),thermodynamic=numeric(0),bezier.corrected=numeric(0),harmonic.mean=numeric(0),stringsAsFactors=F) #initialize a data frame to take the values
    l=1 #initialize l
    for(i in m){ #i<-"stepping_stone"
      wd3<-file.path(wd2,i)
      print(wd3)
      if(!file.exists(wd3)){next}
      setwd(wd3)
      outfile<-scan(file="outfile.txt",what="character",sep="\n") #scan in the outfile, separating at each newline
      
      #get the result from thermodynamic integration
      thermoline<-grep("(1a)",outfile,value=T) #find the line with the thermodynamic likelihood on it
      if(length(thermoline)==0){next}
      thermoline<-strsplit(thermoline,split="=",fixed=T) #split it up
      thermo<-as.numeric(substr(thermoline[[1]][2],start=1,stop=12)) #grab the thermodynamic likelihood
      bezistart<-grep("\\(",strsplit(thermoline[[1]][2],split="")[[1]])+1
      bezier<-as.numeric(substr(thermoline[[1]][2],start=bezistart,stop=bezistart+11)) #and the bezier-corrected value
      #get the harmonic mean
      harmoline<-grep("\\(2\\) H",outfile,value=T) #find the line with harmonic mean likelihood on it
      harmoline<-strsplit(harmoline,split="=",fixed=T) #grab the harmonic mean
      harmo<-as.numeric(substr(harmoline[[1]][2],start=1,stop=12))
      marglike[l,]<-c(i,thermo,bezier,harmo) #add this as a row to the data frame
      l=l+1
    }
    

    
    likelist[[f]]<-marglike #add the dataframe to the list
  }
  
# stop here if you just want one round  
  likelists[[r]]<-likelist
}
setwd(wd)
```

## Model Selection
On each round, and then bind them into a list
```{r model_selection}
modeltable1<-lapply(likelists[[1]],bfcalcs)
modeltable2<-lapply(likelists[[2]],bfcalcs)
modeltable3<-lapply(likelists[[3]],bfcalcs)
modeltables<-list("round1"=modeltable1,"round2"=modeltable2,"round3"=modeltable3)

head(modeltables[[1]],1)
```

## Plot marginal likelihood results from each of 3 runs
```{r}
library(ggplot2)
setwd(wd)
speciesnames<-read.csv("~/github/dongsha/species_names.csv")

pdf(file = "thermodynamic_marginal_likelihoods_final.pdf",width=8.5,height=3)
means<-list()
#plots<-list()
for(dataset in names(modeltables[[1]])){
  likes<-rbind(cbind(modeltables[[1]][[dataset]],rep=1), cbind(modeltables[[2]][[dataset]],rep=2), cbind(modeltables[[3]][[dataset]], rep=3))
  likes$model<-factor(likes$model, m)
  likes<-likes[!(is.na(likes$model)),]
  
speciesname<-speciesnames$Species[which(speciesnames$Working==dataset)]
  
  #likes<-likes[which(likes$bezier.corrected > max(likes$bezier.corrected)-100),]
  y.mean<-as.vector(by(likes$bezier.corrected,likes$model,mean))
  y.sd<-as.vector(by(likes$bezier.corrected,likes$model,sd))
  y.min<-y.mean-((y.sd/sqrt(3))*4.303)
  y.max<-y.mean+((y.sd/sqrt(3))*4.303)

    
  likes.mean<-data.frame(model=factor(m,m),y.mean,y.min,y.max,y.sd)
  means[[dataset]]<-likes.mean
  
  #l<-ggplot(data=likes, aes(x=model,y=bezier.corrected,colour=factor(rep), 
   #                                 shape=factor(rep), size=20 ))
  l<-ggplot(data=likes, aes(x=model,y=bezier.corrected))
  
  l<-l+geom_point(colour="blue", size=3)+
    geom_pointrange(data=likes.mean,y=y.mean,ymin=y.min,ymax=y.max, size=0.5)+
    scale_x_discrete(drop=FALSE)+
    theme(axis.text.y = element_text(size=16),legend.position="none",axis.title.x=element_text(size=16),axis.title.y=element_blank(),plot.title=element_text(size=20))+ggtitle(speciesname)+ylab("Marginal Log-Likelihood")+
    coord_fixed(0.1)+ coord_flip()
  print(l)
#  plots<-c(plots,l)
}
dev.off()


```

## Take the mean marginal likelihoods over three runs and calculate model selection tables.
```{r}
library(perm)

meanlikes<-list()
permtests<-data.frame(matrix(ncol = 8, nrow = 0))
colnames(permtests)<-c(m,"k-means p-value","Best Mean","Second Best Mean","p-value Best Mean > Second Mean", "Ln Bayes Factor")

for(dataset in names(modeltables[[1]])){
  print(dataset)
  likes<-rbind(cbind(modeltables[[1]][[dataset]],rep=1), cbind(modeltables[[2]][[dataset]],rep=2), cbind(modeltables[[3]][[dataset]], rep=3))
  likes$model<-factor(likes$model, m)
  likes<-likes[!(is.na(likes$model)),]
  likes$model<-factor(likes$model, m)
  y.mean<-as.vector(by(likes$bezier.corrected,likes$model,mean)) #take the means for each model
  kmeans.p<-permKS(x = likes$bezier.corrected, g = likes$model, 
                   method="exact.mc")$p.value #k-means non-parametric test to compare all means
  bestmean<-m[order(y.mean,decreasing=T)[1]] # get the highest mean
  secondmean<-m[order(y.mean,decreasing=T)[2]] #get the second best mean
  ttest<-permTS(x=likes$bezier.corrected[which(likes$model==bestmean)],
                y=likes$bezier.corrected[which(likes$model==secondmean)], 
                alternative="greater", method="exact.ce")
  
  
  values<-rbind(y.mean)
  bmvalue<-y.mean[which.max(y.mean)]
	lbf <- 2*(y.mean-bmvalue)
  values<-cbind(values,kmeans.p,bestmean,secondmean,ttest$p.value,sort(lbf)[2])
  
  permtests[dataset,]<-values


	modelrank<-rank(-y.mean)
	modelprob<-exp(lbf/2)/sum(exp(lbf/2),na.rm=T)
	dfall<-cbind("Mean Bezier Corrected ML"=as.numeric(y.mean),"LBF"=as.numeric(lbf),"Rank"=as.numeric(modelrank),"Model_Probability"=as.numeric(modelprob))
	row.names(dfall)<-m
	dfall<-as.data.frame(dfall)
	meanlikes[[dataset]]<-dfall
  
}
```

## Calculate the best models table and save it
```{r}
getmodels2<-function(dfr){
  model1<-row.names(dfr)[which(dfr$Rank==1)]
  model2<-row.names(dfr)[which(dfr$Rank==2)]
  modelprob1<-dfr$Model_Probability[which(dfr$Rank==1)]
  modelprob2<-dfr$Model_Probability[which(dfr$Rank==2)]
  lnBF <- dfr$LBF[which(dfr$Rank ==2)]
  print(model1)
  print(model2)
  print(modelprob1)
  c(model1,modelprob1,model2,modelprob2,lnBF)
}

bestmodeltable<-lapply(meanlikes,getmodels2)
bestmodeltable<-t(as.data.frame(bestmodeltable))
colnames(bestmodeltable)<-c("bestmodel","bestmodelprob","secondbestmodel","secondbestmodelprob","lnBF")
bestmodeltable<-cbind(bestmodeltable,permtests[,c(4,8)])


write.csv(bestmodeltable,file="Final_BestModeltable_Using_Means_of_3reps.csv")
write.csv(permtests,file="Permutation_ttest_results.csv")
save(meanlikes,file="Final_Modeltable_Using_Means_of_3reps.R")
```


## Plot Model Probability

```{r model_probability}

#read in the t-test results
#tt<-read.table(file="~/Dropbox/Crandall_tobo/scripts/Final_BestModeltable_Using_Means_of_3reps.csv",header=T,sep=",")

means<-data.frame(dataset=character(),species=character(),common=character(),
                  models=character(),modelprob=numeric())
#names<-read.csv("Species_names.csv", stringsAsFactors = F)

for(dataset in names(modeltables[[1]])){
  #make a long dataset of model probabilities from each dataset
  species<-speciesnames[which(speciesnames$Working==dataset),2] #lookup the species name

  likes<-rbind(cbind(modeltables[[1]][[dataset]],rep=1), cbind(modeltables[[2]][[dataset]],rep=2), cbind(modeltables[[3]][[dataset]], rep=3))
  likes$model<-factor(likes$model, m)
  likes<-likes[!(is.na(likes$model)),]
  #take the mean model probability
  y.mean<-as.vector(by(likes$modelprob,likes$model,mean))
  #put this back in a data frame with model
  likes.mean<-data.frame(dataset=dataset,species=species,model=factor(m,m),modelprob=y.mean)
  means<-rbind(means,likes.mean)
}

#CODE FOR SORTING SPECIES
#take the value for stepping stone from each model and sort on it
#species<-unique(as.character(means$species)) #make a character vector of all species

#set mean probs for stepping stone that are less than 0.01 to 0 so I can also sort on panmixia
#means[means$model=="stepping.stone" & means$modelprob<0.01,"modelprob"]<-0
#sort it by value of stepping.stone
#species2<-species[order(-tt$ttest_pvalue, #means[means$model=="stepping.stone","modelprob"], #means[means$model=="stepping.stone.1param","modelprob"],
#means[means$model=="hi_lo","modelprob"],
#means[means$model=="empirical","modelprob"],
#means[means$model=="n.island","modelprob"],
#                        decreasing=T)] 
#
#means$model<-factor(means$model,levels=m,labels=c("k <= 14, Stepping-Stone, ~40 parameter","k <= 14, Stepping-Stone, 2 parameter","k = 3, 2 Currents, 7 parameter","k = 2, 1 Current, 4 parameter", "k = 2, High/Low Islands, 4 parameter","k = ? Empirical Structure, ? parameter","k <= 14, n-Island, 2 parameter","k=1, Panmixia, 1 parameter"))


#means$species<-factor(means$species,levels=species2)
means$model<-factor(means$model,levels=m,labels=c("Panmixia","N-Island","Stepping-Stone"))

library(ggplot2)
library(RColorBrewer)

my.cols<-rev(brewer.pal(5,"RdYlBu"))
my.cols<-my.cols[c(1,2,5)]
my.cols[1]<-"#7f7f7f"



mprobs<-ggplot(data=means,mapping=aes(x=species,y=modelprob,fill=model)) + 
  geom_bar(stat="identity") + scale_fill_manual(values=my.cols, guide = guide_legend(title = "Migrate Models")) + 
  theme(axis.text.x=element_text(angle=90, hjust=1,vjust=0.5, color=c(rep("grey25",26),rep("grey70",15))), legend.text = element_text(size = 14), legend.title = element_text(size = 20), axis.text.y= element_text(size = 14), axis.title.y=element_text(size=14)) +
  scale_y_continuous(name="Model Probability") + scale_x_discrete(name="Species")

mprobs

ggsave(filename = "dongsha_bars_final_landscape.pdf", width = 8, height=6,units = "in")
```